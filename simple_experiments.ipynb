{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:40:14.882461: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:40:14.882484: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entood.run import Run, RunSequence\n",
    "from entood.models.contrastive_desc_learning import ContrastiveDescriptionLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_name = tf.test.gpu_device_name()\n",
    "# if not device_name:\n",
    "#     raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:40:33.099109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 13:40:33.099462: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:40:33.099594: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:40:33.099701: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:40:33.099798: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:40:33.099887: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:40:33.099974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:40:33.100067: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:40:33.100158: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:40:33.100171: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-01 13:40:33.100455: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 describer runs.\n",
      "Loading describers...\n",
      "  0% [>...................]\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:40:35.413091: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:35.418336: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:35.424085: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  3\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:40:40.605335: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:40.610031: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:40.614858: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:40.619636: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:40.624814: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  4\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:40:46.097345: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:46.102225: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:46.107287: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:46.114271: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:46.118709: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  6\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:40:51.060835: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:51.064968: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:51.069972: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:51.075480: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:51.086040: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  7\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:40:55.087382: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:55.092755: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:55.097215: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  9\n",
      "model config is  {'channel_noise': 4.0, 'desc_len': 64, 'name': 'describer-64-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:40:58.779795: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:58.784646: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:40:58.790767: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  10\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:03.907375: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:03.910350: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:03.912900: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:03.915436: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:03.919348: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:03.923222: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:03.928324: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:03.930747: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:03.932901: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:03.936871: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  12\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:07.096001: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:07.101267: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:07.106550: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  13\n",
      "model config is  {'channel_noise': 4.0, 'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:11.918409: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:11.924227: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:11.929353: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:11.935740: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:11.940298: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  14\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:16.868130: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:16.874596: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:16.878833: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:16.883909: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:16.887827: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  15\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:21.625442: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:21.630778: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:21.636189: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:21.640628: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:21.646861: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  17\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:25.423067: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:25.427440: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:25.431853: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  18\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:30.264574: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:30.267018: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:30.269516: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:30.272496: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:30.275608: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:30.278567: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:30.281682: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:30.284589: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:30.287179: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:30.290423: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  19\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:34.372172: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:34.378611: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:34.382886: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:34.388594: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:34.393464: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  20\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:38.491976: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:38.494203: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:38.496885: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:38.499122: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:38.501386: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:38.504506: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:38.506759: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:38.508951: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:38.511889: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:38.517993: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  21\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:42.061401: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:42.063540: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:42.065741: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:42.067960: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:42.070017: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:42.072070: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:42.074417: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:42.076642: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:42.079032: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:42.081271: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  22\n",
      "model config is  {'desc_len': 256, 'name': 'describer-256-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:45.545908: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:45.548462: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:45.550915: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:45.553303: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:45.556093: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:45.558553: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:45.561444: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:45.564059: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:45.566486: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:45.568995: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  23\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-3-0'}\n",
      "model config is  {'desc_len': 256, 'name': 'describer-256-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:49.077378: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:49.079405: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:49.081300: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:49.084071: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:49.086453: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:49.088559: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:49.091318: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:49.094532: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:49.097284: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:49.099758: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  25\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n",
      "model config is  {'desc_len': 256, 'name': 'describer-256-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:52.724494: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:52.726676: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:52.728682: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:52.730838: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:52.733295: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:52.735748: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:52.739142: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:52.741558: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:52.743608: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:52.745741: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  27\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-10-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:55.184047: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:55.187919: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:55.195036: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  29\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:41:58.726581: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:58.731287: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:58.735172: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:58.740252: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:41:58.744977: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  30\n",
      "100% [====================] Time taken: 0:01:27\n"
     ]
    }
   ],
   "source": [
    "from entood.analysis.describers_utils import DescribersLoader\n",
    "loader = DescribersLoader(max_train_epochs=10000)\n",
    "describers = loader.load_describers(filter_untrained=False)\n",
    "cf10_datasets = loader.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1d1b788910>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1cec52eaa0>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1d10462e00>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1cec50aef0>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1d102ba8f0>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1d1038e500>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1d10626410>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1cec52e5c0>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1cccc05b10>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1cccbb54e0>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1cccbb5c30>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1ccc885b40>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1ccc68fc10>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1ccc68f9d0>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1ccc241f00>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1ccc106380>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1ccc242650>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1ccc664f10>,\n",
       " <entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner at 0x7f1ccc6668c0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Training $k$</th>\n",
       "      <th>Description Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230067</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.332585</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.158612</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.197208</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.213979</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Loss  Training $k$  Description Len\n",
       "0  0.230067             3               64\n",
       "1  0.332585             5               64\n",
       "2  0.158612             5               64\n",
       "3  0.197208             5               64\n",
       "4  0.213979             3               64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = pd.DataFrame([\n",
    "    {\n",
    "        'Loss': describer.training_summary['loss'],\n",
    "        'Training $k$': describer.training_k,\n",
    "        'Description Len': describer.encoding_size,\n",
    "    }\n",
    "    for describer in describers\n",
    "])\n",
    "\n",
    "losses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Loss  Training $k$  Description Len\n",
      "0   0.230067             3               64\n",
      "1   0.332585             5               64\n",
      "2   0.158612             5               64\n",
      "3   0.197208             5               64\n",
      "4   0.213979             3               64\n",
      "5   0.525112            10               64\n",
      "6   0.093807             3               64\n",
      "7   0.199878             5               64\n",
      "8   0.156573             5               64\n",
      "9   0.126543             3              512\n",
      "10  0.349414            10              512\n",
      "11  0.180110             5              512\n",
      "12  2.303647            10              512\n",
      "13  0.405202            10              512\n",
      "14  0.417200            10              256\n",
      "15  0.396043            10              256\n",
      "16  0.366725            10              256\n",
      "17  0.135536             3               64\n",
      "18  0.203773             5               64\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating (k=3) [1/11]\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.0000e+00 - acc: 0.9711\n",
      "150/150 [==============================] - 12s 69ms/step - loss: 0.0000e+00 - acc: 0.9661\n",
      "\n",
      "Evaluating (k=5) [2/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:20:31.752787: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:20:31.768306: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:20:31.780840: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 15s 92ms/step - loss: 0.0000e+00 - acc: 0.9354\n",
      "150/150 [==============================] - 17s 98ms/step - loss: 0.0000e+00 - acc: 0.9400\n",
      "\n",
      "Evaluating (k=5) [3/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:21:03.630554: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:21:03.654196: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:21:03.674188: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:21:03.697707: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:21:03.718180: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 14s 88ms/step - loss: 0.0000e+00 - acc: 0.9333\n",
      "150/150 [==============================] - 17s 99ms/step - loss: 0.0000e+00 - acc: 0.9359\n",
      "\n",
      "Evaluating (k=5) [4/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:21:34.975751: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:21:34.993111: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:21:35.011893: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:21:35.030923: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:21:35.047138: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 14s 89ms/step - loss: 0.0000e+00 - acc: 0.9707\n",
      "150/150 [==============================] - 17s 97ms/step - loss: 0.0000e+00 - acc: 0.9708\n",
      "\n",
      "Evaluating (k=3) [5/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:22:06.426505: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:06.443361: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:06.461074: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:06.477672: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:06.494529: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 10s 61ms/step - loss: 0.0000e+00 - acc: 0.9520\n",
      "150/150 [==============================] - 12s 68ms/step - loss: 0.0000e+00 - acc: 0.9636\n",
      "\n",
      "Evaluating (k=10) [6/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:22:27.962779: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:27.977430: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:27.993537: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 12s 73ms/step - loss: 0.0000e+00 - acc: 0.5156\n",
      "150/150 [==============================] - 15s 81ms/step - loss: 0.0000e+00 - acc: 0.5129\n",
      "\n",
      "Evaluating (k=3) [7/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:22:54.972406: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:54.982813: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:54.996555: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:55.006375: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:55.016567: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:55.026440: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:55.036117: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:55.045663: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:55.055984: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:22:55.064925: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 10s 62ms/step - loss: 0.0000e+00 - acc: 0.9578\n",
      "150/150 [==============================] - 12s 68ms/step - loss: 0.0000e+00 - acc: 0.9547\n",
      "\n",
      "Evaluating (k=5) [8/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:23:16.660568: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:23:16.675903: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:23:16.692262: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 15s 91ms/step - loss: 0.0000e+00 - acc: 0.9622\n",
      "150/150 [==============================] - 17s 97ms/step - loss: 0.0000e+00 - acc: 0.9767\n",
      "\n",
      "Evaluating (k=5) [9/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:23:48.292524: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:23:48.309707: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:23:48.327363: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:23:48.344793: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:23:48.360066: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 14s 88ms/step - loss: 0.0000e+00 - acc: 0.9044\n",
      "150/150 [==============================] - 17s 98ms/step - loss: 0.0000e+00 - acc: 0.8943\n",
      "\n",
      "Evaluating (k=3) [10/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:24:19.570074: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:24:19.586739: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:24:19.603159: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:24:19.618839: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:24:19.635816: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 10s 62ms/step - loss: 0.0000e+00 - acc: 0.8982\n",
      "150/150 [==============================] - 11s 67ms/step - loss: 0.0000e+00 - acc: 0.9029\n",
      "\n",
      "Evaluating (k=5) [11/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:24:41.284160: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:24:41.299219: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:24:41.312658: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 14s 90ms/step - loss: 0.0000e+00 - acc: 0.7799\n",
      "150/150 [==============================] - 17s 99ms/step - loss: 0.0000e+00 - acc: 0.7816\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:25:12.931147: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:25:12.948898: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:25:12.965771: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:25:12.983799: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:25:13.001360: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Look at accuracies\n",
    "\n",
    "desc_len_64_describers = [describer for describer in describers if describer.encoding_size == 64]\n",
    "\n",
    "steps = 150\n",
    "\n",
    "items = []\n",
    "for i, describer in enumerate(desc_len_64_describers):\n",
    "    k = describer.training_k\n",
    "    dataset = cf10_datasets[k]\n",
    "    train_ds = dataset['train_ds']\n",
    "    test_ds = dataset['val_ds']\n",
    "    \n",
    "    print(f'Evaluating ({k=}) [{i+1}/{len(desc_len_64_describers)}]')\n",
    "    *_, test_acc = describer.evaluate(test_ds, steps=steps)\n",
    "    *_, train_acc = describer.evaluate(train_ds, steps=steps)\n",
    "    print()\n",
    "    \n",
    "    items.append({\n",
    "        'Describer ID': describer.identifier,\n",
    "        'Training Accuracy': train_acc,\n",
    "        'Test Accuracy': test_acc,\n",
    "        '$k$': k\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overfit_df = pd.DataFrame(items)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=overfit_df, x='$k$', y='Training Accuracy', label='Training')\n",
    "sns.lineplot(data=overfit_df, x='$k$', y='Test Accuracy', label='Test')\n",
    "plt.xticks(overfit_df['$k$'].unique())\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating (k=3) [1/5]\n",
      "150/150 [==============================] - 9s 53ms/step - loss: 0.0000e+00 - acc: 0.8259\n",
      "150/150 [==============================] - 10s 57ms/step - loss: 0.0000e+00 - acc: 0.8367\n",
      "\n",
      "Evaluating (k=10) [2/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 12:37:17.297193: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:37:17.310370: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:37:17.324384: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 11s 62ms/step - loss: 0.0000e+00 - acc: 0.7510\n",
      "150/150 [==============================] - 12s 69ms/step - loss: 0.0000e+00 - acc: 0.7419\n",
      "\n",
      "Evaluating (k=5) [3/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 12:37:40.268619: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:37:40.277599: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:37:40.285673: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:37:40.293536: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:37:40.302272: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:37:40.310687: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:37:40.319272: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:37:40.327207: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:37:40.335842: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:37:40.344185: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 12s 75ms/step - loss: 0.0000e+00 - acc: 0.6637\n",
      "150/150 [==============================] - 14s 84ms/step - loss: 0.0000e+00 - acc: 0.6604\n",
      "\n",
      "Evaluating (k=10) [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 12:38:07.000409: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:07.015793: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:07.032433: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:07.047562: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:07.061326: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 11s 64ms/step - loss: 0.0000e+00 - acc: 0.1769\n",
      "150/150 [==============================] - 12s 70ms/step - loss: 0.0000e+00 - acc: 0.1692\n",
      "\n",
      "Evaluating (k=10) [5/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 12:38:30.162450: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:30.171527: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:30.180856: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:30.190135: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:30.199080: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:30.208669: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:30.218517: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:30.227356: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:30.236492: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:30.244548: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 11s 63ms/step - loss: 0.0000e+00 - acc: 0.4519\n",
      "150/150 [==============================] - 12s 69ms/step - loss: 0.0000e+00 - acc: 0.4469\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 12:38:53.464105: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:53.472333: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:53.480526: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:53.488903: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:53.497518: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:53.505240: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:53.514617: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:53.525730: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:53.534099: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 12:38:53.541254: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "desc_len_512_describers = [describer for describer in describers if describer.encoding_size == 512]\n",
    "\n",
    "steps = 150\n",
    "\n",
    "items = []\n",
    "for i, describer in enumerate(desc_len_512_describers):\n",
    "    k = describer.training_k\n",
    "    dataset = cf10_datasets[k]\n",
    "    train_ds = dataset['train_ds']\n",
    "    test_ds = dataset['val_ds']\n",
    "    \n",
    "    print(f'Evaluating ({k=}) [{i+1}/{len(desc_len_512_describers)}]')\n",
    "    *_, test_acc = describer.evaluate(test_ds, steps=steps)\n",
    "    *_, train_acc = describer.evaluate(train_ds, steps=steps)\n",
    "    print()\n",
    "    \n",
    "    items.append({\n",
    "        'Describer ID': describer.identifier,\n",
    "        'Training Accuracy': train_acc,\n",
    "        'Test Accuracy': test_acc,\n",
    "        '$k$': k\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_df = pd.DataFrame(items)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=overfit_df, x='$k$', y='Training Accuracy', label='Training')\n",
    "sns.lineplot(data=overfit_df, x='$k$', y='Test Accuracy', label='Test')\n",
    "plt.xticks(overfit_df['$k$'].unique())\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner object at 0x7fc93eb241c0>\n",
      "<entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner object at 0x7fc91041abc0>\n",
      "<entood.models.contrastive_desc_learning.ContrastiveDescriptionLearner object at 0x7fc91010d6c0>\n"
     ]
    }
   ],
   "source": [
    "desc_len_64_describers = [describer for describer in describers if describer.encoding_size == 64]\n",
    "\n",
    "steps = 150\n",
    "\n",
    "items = []\n",
    "for i, describer in enumerate(desc_len_64_describers):\n",
    "    k = describer.training_k\n",
    "    print(describer)\n",
    "    dataset = cf10_datasets[k]\n",
    "    train_ds = dataset['train_ds']\n",
    "    test_ds = dataset['val_ds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Describer ID': -6401867250448639332,\n",
       "  'Training Accuracy': 0.8366666436195374,\n",
       "  'Test Accuracy': 0.8259375095367432,\n",
       "  '$k$': 3},\n",
       " {'Describer ID': -4164375129428635944,\n",
       "  'Training Accuracy': 0.7418749928474426,\n",
       "  'Test Accuracy': 0.7510416507720947,\n",
       "  '$k$': 10},\n",
       " {'Describer ID': 4878991708436124311,\n",
       "  'Training Accuracy': 0.6604166626930237,\n",
       "  'Test Accuracy': 0.6637499928474426,\n",
       "  '$k$': 5},\n",
       " {'Describer ID': 5708171424118247375,\n",
       "  'Training Accuracy': 0.1691666692495346,\n",
       "  'Test Accuracy': 0.17687499523162842,\n",
       "  '$k$': 10},\n",
       " {'Describer ID': -5757787929021727414,\n",
       "  'Training Accuracy': 0.4468750059604645,\n",
       "  'Test Accuracy': 0.4518750011920929,\n",
       "  '$k$': 10}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load specific describers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:33:27.442838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 13:33:27.443087: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:33:27.445229: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:33:27.447366: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:33:27.449612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:33:27.451787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:33:27.453991: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:33:27.456223: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:33:27.458405: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-05-01 13:33:27.458425: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-01 13:33:27.458725: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 describer runs.\n",
      "Loading describers...\n",
      "  0% [>...................]\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:33:29.195350: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:29.199779: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:29.203799: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  3\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:33:33.561206: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:33.565344: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:33.569321: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:33.573761: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:33.577342: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  4\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:33:37.335327: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:37.340240: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:37.345406: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:37.350150: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:37.354931: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  6\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:33:41.176489: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:41.181563: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:41.185465: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:41.191949: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:41.197736: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  7\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:33:44.696826: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:44.705153: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:44.711899: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  9\n",
      "model config is  {'channel_noise': 4.0, 'desc_len': 64, 'name': 'describer-64-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:33:48.817445: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:48.828281: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:48.833506: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  10\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:33:53.364958: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:53.367426: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:53.370050: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:53.372161: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:53.374475: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:53.377787: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:53.380259: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:53.382762: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:53.385677: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:53.392203: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  12\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:33:56.109781: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:56.117728: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:33:56.122899: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  13\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:00.758894: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:00.762824: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:00.767644: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:00.772460: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:00.776705: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  14\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:05.690863: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:05.697367: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:05.702849: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:05.709251: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:05.714044: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  16\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:09.472588: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:09.479144: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:09.484081: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  17\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:14.646034: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:14.648015: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:14.650433: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:14.653425: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:14.656314: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:14.658817: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:14.661590: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:14.664739: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:14.667991: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:14.671276: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  18\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:18.872707: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:18.877938: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:18.884750: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:18.889833: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:18.895786: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  19\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:23.964110: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:23.968714: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:23.972404: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:23.975642: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:23.979528: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:23.982719: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:23.985871: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:23.990132: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:23.993278: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:23.996416: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  20\n",
      "model config is  {'desc_len': 512, 'name': 'describer-512-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:28.670427: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:28.683406: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:28.686228: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:28.689793: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:28.692454: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:28.695215: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:28.699731: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:28.702564: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:28.705126: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:28.708945: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  21\n",
      "model config is  {'desc_len': 256, 'name': 'describer-256-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:33.292430: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:33.294503: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:33.297651: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:33.300542: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:33.303424: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:33.306461: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:33.308963: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:33.311315: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:33.314034: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:33.317302: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  22\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-3-0'}\n",
      "model config is  {'desc_len': 256, 'name': 'describer-256-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:37.883303: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:37.886142: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:37.888511: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:37.891223: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:37.894330: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:37.896639: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:37.899392: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:37.902910: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:37.905419: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:37.908310: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  24\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n",
      "model config is  {'desc_len': 256, 'name': 'describer-256-10-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:42.471616: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:42.474845: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:42.477927: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:42.481473: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:42.484221: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:42.487117: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:42.490942: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:42.493966: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:42.496910: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:42.500701: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  26\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-10-0'}\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-3-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:45.741593: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:45.746431: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:45.752729: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  28\n",
      "model config is  {'desc_len': 64, 'name': 'describer-64-5-0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:34:50.980131: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:50.984753: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:50.990517: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:50.995389: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:34:51.001357: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully returning a describer!\n",
      "num processed:  29\n",
      "100% [====================] Time taken: 0:01:25\n"
     ]
    }
   ],
   "source": [
    "from entood.analysis.describers_utils import DescribersLoader\n",
    "loader = DescribersLoader(max_train_epochs=10000)\n",
    "describers = loader.load_describers(filter_untrained=False)\n",
    "cf10_datasets = loader.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "4.0\n",
      "0.5\n",
      "0.5\n",
      "4.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "for describer in describers:\n",
    "    print(describer.channel_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating (k=3) [1/2]\n",
      "150/150 [==============================] - 10s 54ms/step - loss: 0.0000e+00 - acc: 0.9846\n",
      "150/150 [==============================] - 10s 57ms/step - loss: 0.0000e+00 - acc: 0.9847\n",
      "\n",
      "Evaluating (k=5) [2/2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:43:38.421652: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:43:38.434827: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:43:38.449494: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 12s 75ms/step - loss: 0.0000e+00 - acc: 0.9639\n",
      "150/150 [==============================] - 14s 83ms/step - loss: 0.0000e+00 - acc: 0.9645\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:44:04.972512: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:44:04.985647: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:44:04.998971: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:44:05.012304: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-01 13:44:05.028237: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Want models with channel noise 4.0\n",
    "\n",
    "# Look at accuracies\n",
    "\n",
    "noise_4_describers = [describer for describer in describers if describer.channel_noise == 4.0]\n",
    "\n",
    "steps = 150\n",
    "\n",
    "items = []\n",
    "for i, describer in enumerate(noise_4_describers):\n",
    "    k = describer.training_k\n",
    "    dataset = cf10_datasets[k]\n",
    "    train_ds = dataset['train_ds']\n",
    "    test_ds = dataset['val_ds']\n",
    "    \n",
    "    print(f'Evaluating ({k=}) [{i+1}/{len(noise_4_describers)}]')\n",
    "    *_, test_acc = describer.evaluate(test_ds, steps=steps)\n",
    "    *_, train_acc = describer.evaluate(train_ds, steps=steps)\n",
    "    print()\n",
    "    \n",
    "    items.append({\n",
    "        'Describer ID': describer.identifier,\n",
    "        'Training Accuracy': train_acc,\n",
    "        'Test Accuracy': test_acc,\n",
    "        '$k$': k\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env2",
   "language": "python",
   "name": "tf-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
